\relax 
\bibstyle{acl_natbib}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{NealEtal17}
\citation{Howl91}
\citation{Luto97}
\citation{Juol08}
\citation{MostWall63,MostWall84}
\citation{NiloEtal99}
\citation{NiloBino03}
\citation{HughEtal12}
\citation{NealEtal17}
\citation{More17,More00}
\@LN@col{1}
\@LN{0}{0}
\@LN{1}{0}
\@LN{2}{0}
\@LN{3}{0}
\@LN{4}{0}
\@LN{5}{0}
\@LN{6}{0}
\@LN{7}{0}
\@LN{8}{0}
\@LN{9}{0}
\@LN{10}{0}
\@LN{11}{0}
\@LN{12}{0}
\@LN{13}{0}
\@LN{14}{0}
\@LN{15}{0}
\@LN{16}{0}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@LN{17}{0}
\@LN{18}{0}
\@LN{19}{0}
\@LN{20}{0}
\@LN{21}{0}
\@LN{22}{0}
\@LN{23}{0}
\@LN{24}{0}
\@LN{25}{0}
\@LN{26}{0}
\@LN{27}{0}
\@LN{28}{0}
\@LN{29}{0}
\@LN{30}{0}
\@LN{31}{0}
\@LN{32}{0}
\@LN{33}{0}
\@LN{34}{0}
\@LN{35}{0}
\@LN@col{2}
\@LN{36}{0}
\@LN{37}{0}
\@LN{38}{0}
\@LN{39}{0}
\@LN{40}{0}
\@LN{41}{0}
\@LN{42}{0}
\@LN{43}{0}
\@LN{44}{0}
\@LN{45}{0}
\@LN{46}{0}
\@LN{47}{0}
\@LN{48}{0}
\@LN{49}{0}
\@LN{50}{0}
\@LN{51}{0}
\@LN{52}{0}
\@LN{53}{0}
\@LN{54}{0}
\@LN{55}{0}
\@LN{56}{0}
\@LN{57}{0}
\@LN{58}{0}
\@LN{59}{0}
\@LN{60}{0}
\@LN{61}{0}
\@LN{62}{0}
\@LN{63}{0}
\@LN{64}{0}
\@LN{65}{0}
\@LN{66}{0}
\@LN{67}{0}
\@LN{68}{0}
\@LN{69}{0}
\citation{LoshHutt19}
\@LN@col{1}
\@LN{70}{1}
\@LN{71}{1}
\@LN{72}{1}
\@LN{73}{1}
\@LN{74}{1}
\@LN{75}{1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}\protected@file@percent }
\@LN{76}{1}
\@LN{77}{1}
\@LN{78}{1}
\@LN{79}{1}
\@LN{80}{1}
\@LN{81}{1}
\@LN{82}{1}
\@LN{83}{1}
\@LN{84}{1}
\@LN{85}{1}
\@LN{86}{1}
\@LN{87}{1}
\@LN{88}{1}
\@LN{89}{1}
\@LN{90}{1}
\@LN{91}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data and Data Preprocessing}{2}{subsection.2.1}\protected@file@percent }
\@LN{92}{1}
\@LN{93}{1}
\@LN{94}{1}
\@LN{95}{1}
\@LN{96}{1}
\@LN{97}{1}
\@LN{98}{1}
\@LN{99}{1}
\@LN{100}{1}
\@LN{101}{1}
\@LN{102}{1}
\@LN{103}{1}
\@LN{104}{1}
\@LN{105}{1}
\@LN{106}{1}
\@LN{107}{1}
\@LN{108}{1}
\@LN{109}{1}
\@LN{110}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model Training}{2}{subsection.2.2}\protected@file@percent }
\@LN{111}{1}
\@LN{112}{1}
\@LN{113}{1}
\@LN{114}{1}
\@LN@col{2}
\@LN{115}{1}
\@LN{116}{1}
\@LN{117}{1}
\@LN{118}{1}
\@LN{119}{1}
\@LN{120}{1}
\@LN{121}{1}
\@LN{122}{1}
\@LN{123}{1}
\@LN{124}{1}
\@LN{125}{1}
\@LN{126}{1}
\@LN{127}{1}
\@LN{128}{1}
\@LN{129}{1}
\@LN{130}{1}
\@LN{131}{1}
\@LN{132}{1}
\@LN{133}{1}
\@LN{134}{1}
\@LN{135}{1}
\@LN{136}{1}
\@LN{137}{1}
\@LN{138}{1}
\@LN{139}{1}
\@LN{140}{1}
\@LN{141}{1}
\@LN{142}{1}
\@LN{143}{1}
\@LN{144}{1}
\@LN{145}{1}
\@LN{146}{1}
\@LN{147}{1}
\@LN{148}{1}
\@LN{149}{1}
\@LN{150}{1}
\@LN{151}{1}
\@LN{152}{1}
\@LN{153}{1}
\@LN{154}{1}
\@LN{155}{1}
\@LN{156}{1}
\@LN@col{1}
\@LN{157}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Predictive Comparison Testing}{3}{subsection.2.3}\protected@file@percent }
\@LN{158}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Baum vs. Thompson}{3}{subsubsection.2.3.1}\protected@file@percent }
\@LN{159}{2}
\@LN{160}{2}
\@LN{161}{2}
\@LN{162}{2}
\@LN{163}{2}
\@LN{164}{2}
\@LN{165}{2}
\@LN{166}{2}
\@LN{167}{2}
\@LN{168}{2}
\@LN{169}{2}
\@LN{170}{2}
\@LN{171}{2}
\@LN{172}{2}
\@LN{173}{2}
\@LN{174}{2}
\@LN{175}{2}
\@LN{176}{2}
\@LN{177}{2}
\@LN{178}{2}
\@LN{179}{2}
\@LN{180}{2}
\@LN{181}{2}
\@LN{182}{2}
\@LN{183}{2}
\@LN{184}{2}
\@LN{185}{2}
\@LN{186}{2}
\@LN{187}{2}
\@LN{188}{2}
\@LN{189}{2}
\@LN{190}{2}
\@LN{191}{2}
\@LN{192}{2}
\@LN{193}{2}
\@LN{194}{2}
\@LN{195}{2}
\@LN{196}{2}
\@LN{197}{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Eight-Author Comparison}{3}{subsubsection.2.3.2}\protected@file@percent }
\@LN{198}{2}
\@LN{199}{2}
\@LN{200}{2}
\@LN{201}{2}
\@LN{202}{2}
\@LN@col{2}
\@LN{203}{2}
\@LN{204}{2}
\@LN{205}{2}
\@LN{206}{2}
\@LN{207}{2}
\@LN{208}{2}
\@LN{209}{2}
\@LN{210}{2}
\@LN{211}{2}
\@LN{212}{2}
\@LN{213}{2}
\@LN{214}{2}
\@LN{215}{2}
\@LN{216}{2}
\@LN{217}{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}$t$-tests}{3}{subsection.2.4}\protected@file@percent }
\@LN{218}{2}
\@LN{219}{2}
\@LN{220}{2}
\@LN{221}{2}
\@LN{222}{2}
\@LN{223}{2}
\@LN{224}{2}
\@LN{225}{2}
\@LN{226}{2}
\@LN{227}{2}
\@LN{228}{2}
\@LN{229}{2}
\@LN{230}{2}
\@LN{231}{2}
\@LN{232}{2}
\@LN{233}{2}
\@LN{234}{2}
\@LN{235}{2}
\@LN{236}{2}
\@LN{237}{2}
\@LN{238}{2}
\@LN{239}{2}
\@LN{240}{2}
\@LN{241}{2}
\@LN{242}{2}
\@LN{243}{2}
\@LN{244}{2}
\@LN{245}{2}
\@LN{246}{2}
\@LN{247}{2}
\@LN{248}{2}
\@LN{249}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {A.} Average cross-entropy loss on evaluation texts for models trained on Baum and Thompson. Each model is trained with a different random seed; we report the mean cross-entropy loss across 10 random seeds, with error bars indicating a 95\% confidence interval. \textbf  {B.} Average cross-entropy loss on evaluation texts across all eight authors. Error bars denote 95\% confidence intervals over 10 random seeds. \textbf  {C.} $t$-test results by author for the first 500 training epochs. \textbf  {D.} Averaged $t$-test results for the first 500 training epochs.}}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:losses-and-ttests}{{1}{4}{\textbf {A.} Average cross-entropy loss on evaluation texts for models trained on Baum and Thompson. Each model is trained with a different random seed; we report the mean cross-entropy loss across 10 random seeds, with error bars indicating a 95\% confidence interval. \textbf {B.} Average cross-entropy loss on evaluation texts across all eight authors. Error bars denote 95\% confidence intervals over 10 random seeds. \textbf {C.} $t$-test results by author for the first 500 training epochs. \textbf {D.} Averaged $t$-test results for the first 500 training epochs}{figure.caption.1}{}}
\@LN@col{1}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces $t$-test results for each author on final losses}}{4}{table.caption.2}\protected@file@percent }
\newlabel{tab:author_t_tests}{{1}{4}{$t$-test results for each author on final losses}{table.caption.2}{}}
\@LN{250}{3}
\@LN{251}{3}
\@LN{252}{3}
\@LN{253}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Classification}{4}{subsection.2.5}\protected@file@percent }
\@LN{254}{3}
\@LN{255}{3}
\@LN{256}{3}
\@LN{257}{3}
\@LN{258}{3}
\@LN{259}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Stylometric Distance}{4}{subsection.2.6}\protected@file@percent }
\@LN{260}{3}
\@LN{261}{3}
\@LN{262}{3}
\@LN{263}{3}
\@LN{264}{3}
\@LN{265}{3}
\@LN@col{2}
\@LN{266}{3}
\@LN{267}{3}
\@LN{268}{3}
\@LN{269}{3}
\@LN{270}{3}
\@LN{271}{3}
\@LN{272}{3}
\@LN{273}{3}
\@LN{274}{3}
\@LN{275}{3}
\@LN{276}{3}
\@LN{277}{3}
\@LN{278}{3}
\@LN{279}{3}
\@LN{280}{3}
\@LN{281}{3}
\@LN{282}{3}
\@LN{283}{3}
\@LN{284}{3}
\@LN{285}{3}
\@LN{286}{3}
\@LN{287}{3}
\@LN{288}{3}
\@LN{289}{3}
\@LN{290}{3}
\@LN{291}{3}
\@LN{292}{3}
\@LN{293}{3}
\@LN{294}{3}
\bibdata{custom}
\bibcite{NiloEtal99}{{1}{1999}{{Binongo and Smith}}{{}}}
\bibcite{NiloBino03}{{2}{2003}{{Binongo}}{{}}}
\bibcite{Howl91}{{3}{1991}{{Howland}}{{}}}
\bibcite{HughEtal12}{{4}{2012}{{Hughes et~al.}}{{Hughes, Foti, Krakauer, and Rockmore}}}
\bibcite{Juol08}{{5}{2008}{{Juola}}{{}}}
\bibcite{LoshHutt19}{{6}{2019}{{Loshchilov and Hutter}}{{}}}
\bibcite{Luto97}{{7}{1897}{{Lutos{\l }awski}}{{}}}
\bibcite{More00}{{8}{2000}{{Moretti}}{{}}}
\bibcite{More17}{{9}{2017}{{Moretti}}{{}}}
\bibcite{MostWall63}{{10}{1963}{{Mosteller and Wallace}}{{}}}
\bibcite{MostWall84}{{11}{1984}{{Mosteller and Wallace}}{{}}}
\bibcite{NealEtal17}{{12}{2017}{{Neal et~al.}}{{Neal, Sundararajan, Fatima, Yan, Xiang, and Woodard}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {A.} A heatmap of the average loss values when we compute losses on comparison texts ($x$-axis) language models trained on the 8 authors' texts ($y$-axis). Each cell represents the mean loss value across 10 training seeds, with lower values (lighter colors) indicating better model performance. The diagonal elements show how well models perform on their training author's own texts. \textbf  {B.} Multidimensional scaling plot, where the distances between the authors are proportional to the correlations between the corresponding rows in the loss matrix shown in Panel A, excluding diagonal entries.}}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:loss-mds}{{2}{5}{\textbf {A.} A heatmap of the average loss values when we compute losses on comparison texts ($x$-axis) language models trained on the 8 authors' texts ($y$-axis). Each cell represents the mean loss value across 10 training seeds, with lower values (lighter colors) indicating better model performance. The diagonal elements show how well models perform on their training author's own texts. \textbf {B.} Multidimensional scaling plot, where the distances between the authors are proportional to the correlations between the corresponding rows in the loss matrix shown in Panel A, excluding diagonal entries}{figure.caption.3}{}}
\@LN@col{1}
\@LN{295}{4}
\@LN{296}{4}
\@LN{297}{4}
\@LN{298}{4}
\@LN{299}{4}
\@LN{300}{4}
\@LN{301}{4}
\@LN{302}{4}
\@LN{303}{4}
\@LN{304}{4}
\@LN{305}{4}
\@LN{306}{4}
\@LN{307}{4}
\@LN{308}{4}
\@LN{309}{4}
\@LN{310}{4}
\@LN{311}{4}
\@LN{312}{4}
\@LN{313}{4}
\@LN{314}{4}
\@LN{315}{4}
\@LN{316}{4}
\@LN{317}{4}
\@LN{318}{4}
\@LN@col{2}
\@LN{319}{4}
\@LN{320}{4}
\@LN{321}{4}
\@LN{322}{4}
\@LN{323}{4}
\@LN{324}{4}
\@LN{325}{4}
\@LN{326}{4}
\@LN{327}{4}
\@LN{328}{4}
\@LN{329}{4}
\@LN{330}{4}
\@LN{331}{4}
\@LN{332}{4}
\@LN{333}{4}
\@LN{334}{4}
\@LN{335}{4}
\@LN{336}{4}
\@LN{337}{4}
\@LN{338}{4}
\@LN{339}{4}
\@LN{340}{4}
\@LN{341}{4}
\@LN{342}{4}
\@LN@col{1}
\@LN{343}{5}
\@writefile{toc}{\contentsline {section}{\numberline {A}Authors, Books, Tokens}{6}{appendix.A}\protected@file@percent }
\newlabel{sec:appendixA}{{A}{6}{Authors, Books, Tokens}{appendix.A}{}}
\@LN@col{2}
\@LN@col{1}
\@LN@col{2}
\@LN@col{1}
\@LN@col{2}
\gdef \@abspage@last{8}
